from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_google_community.search import GoogleSearchAPIWrapper

from langchain_openai.chat_models import ChatOpenAI
import sqlite3
from dotenv import load_dotenv

load_dotenv()

app = FastAPI()

# React ã®é–‹ç™ºã‚µãƒ¼ãƒãƒ¼ï¼ˆä¾‹: http://localhost:5173ï¼‰ã‚’è¨±å¯
origins = [
    "http://localhost:5173",  # Vite ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ¼ãƒˆ
    "http://localhost:3000",  # CRA ã®å ´åˆ
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # è¨±å¯ã™ã‚‹ã‚ªãƒªã‚¸ãƒ³
    allow_credentials=True,
    allow_methods=["*"],    # ã™ã¹ã¦ã®HTTPãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¨±å¯
    allow_headers=["*"],    # ã™ã¹ã¦ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨±å¯
)

# ä¼šè©±å±¥æ­´ã®ã‚¹ãƒˆã‚¢
store = {}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã”ã¨ã®ä¼šè©±å±¥æ­´ã®å–å¾—
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
chat_prompt  = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}"),
    ]
)

# ãƒ¢ãƒ‡ãƒ«ä½œæˆ
chat_model = ChatOpenAI(model="gpt-4o-mini")

# ãƒãƒ£ãƒƒãƒˆRunnableï¼ˆå±¥æ­´ä¿å­˜ã‚ã‚Šï¼‰
chat_runnable = RunnableWithMessageHistory(
    runnable = chat_prompt  | chat_model,
    get_session_history=get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

# Google Search APIã®è¨­å®š
search_tool = GoogleSearchAPIWrapper()


def run_chat_mode(session_id: str, user_input: str):
    """ğŸ’¬ é€šå¸¸ã®ä¼šè©±ãƒ¢ãƒ¼ãƒ‰"""
    response = chat_runnable.invoke(
        {"input": user_input},
        config={"configurable": {"session_id": session_id}}
    )
    return response.content

def run_search_mode(session_id: str, user_input: str) -> str:
    """ğŸŒ Googleæ¤œç´¢ãƒ¢ãƒ¼ãƒ‰"""
    memory = get_session_history(session_id)
    query = user_input
    for kw in ["æ¤œç´¢", "èª¿ã¹ã¦", "æ¢ã—ã¦"]:
        query = query.replace(kw, "")
    query = query.strip()
    if not query:
        return "ä½•ã‚’æ¤œç´¢ã™ã‚Œã°ã‚ˆã„ã®ã‹æ•™ãˆã¦ãã ã•ã„ã€‚"

    try:
        result = search_tool.run(query)
    except Exception as e:
        return f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
    # run_search_mode.search_cache[query] = result

    # çµæœãŒé•·ã„å ´åˆã¯è¦ç´„
    if len(result) > 1500:
        summary = chat_model.invoke(
            f"ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’ã‚ã‹ã‚Šã‚„ã™ã200æ–‡å­—ä»¥å†…ã«è¦ç´„ã—ã¦ãã ã•ã„:\n\n{result}"
        ).content
        result = summary

    memory.add_user_message(user_input)
    memory.add_ai_message(result)
    return f"ğŸ” **{query}** ã®æ¤œç´¢çµæœ:\n{result}"


# ãƒ¢ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®š
def detect_mode(user_input: str) -> str:
    prompt = f"æ¬¡ã®æ–‡ç« ãŒæ¤œç´¢æŒ‡ç¤ºã‹æ—¥å¸¸ä¼šè©±ã‹åˆ¤å®šã—ã¦ãã ã•ã„ã€‚ã€Œæ¤œç´¢ã€ãªã‚‰ searchã€ã€Œä¼šè©±ã€ãªã‚‰ chat ã‚’è¿”ã—ã¦ãã ã•ã„:\n{user_input}"
    response = chat_model.invoke(prompt)
    return "search" if "search" in response.content.lower() else "chat"

class ChatRequest(BaseModel):
    message: str
    mode: str | None = None  # "chat" or "search" or Noneï¼ˆè‡ªå‹•åˆ¤å®šï¼‰



@app.post("/")
async def chat(req: ChatRequest):
    print(req.message)
    session_id = "example_session"
    user_input = req.message.strip()

    # ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    mode = req.mode or detect_mode(user_input)
    
    if user_input.lower() == "çµ‚äº†":
        return {"response": "ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚"}

    if user_input.lower() == "å±¥æ­´å‰Šé™¤":
        store.pop(session_id, None)
        return {"response": "å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚"}
    
    # å„ãƒ¢ãƒ¼ãƒ‰ã¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    if mode == "search":
        answer = run_search_mode(session_id, user_input)
    else:
        answer = run_chat_mode(session_id, user_input)

    return {"mode": mode, "response": answer}

